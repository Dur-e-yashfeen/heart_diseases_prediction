import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, f1_score, roc_auc_score, roc_curve
from sklearn.feature_selection import SelectKBest, f_classif

# Load the dataset
def load_data(filepath):
    data = pd.read_csv(filepath)
    return data

# Perform EDA
def perform_eda(data):
    print("Dataset Info:")
    print(data.info())

    print("\nSummary Statistics:")
    print(data.describe())

    print("\nCorrelation Matrix:")
    plt.figure(figsize=(10, 8))
    sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt='.2f')
    plt.title("Correlation Matrix")
    plt.show()

    print("\nTarget Distribution:")
    sns.countplot(x='target', data=data)
    plt.title("Distribution of Target Variable (Heart Disease)")
    plt.show()

# Preprocess the data
def preprocess_data(data):
    # Handle missing values (if any)
    data = data.fillna(data.median())

    # Separate features and target
    X = data.drop('target', axis=1)
    y = data['target']

    # Feature selection using SelectKBest
    selector = SelectKBest(f_classif, k=10)
    X_selected = selector.fit_transform(X, y)

    # Get selected feature names
    selected_features = X.columns[selector.get_support()]
    print("\nSelected Features:", selected_features)

    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)

    # Standardize the features
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    return X_train, X_test, y_train, y_test, selected_features

# Train and evaluate models
def train_and_evaluate(X_train, X_test, y_train, y_test):
    # Gradient Boosting Classifier
    gb = GradientBoostingClassifier(random_state=42)
    gb.fit(X_train, y_train)
    y_pred_gb = gb.predict(X_test)

    # SVM Classifier
    svm = SVC(random_state=42, probability=True)
    svm.fit(X_train, y_train)
    y_pred_svm = svm.predict(X_test)

    # Neural Network Classifier
    nn = MLPClassifier(random_state=42, max_iter=1000)
    nn.fit(X_train, y_train)
    y_pred_nn = nn.predict(X_test)

    # Evaluate performance
    print("\nGradient Boosting Classification Report:")
    print(classification_report(y_test, y_pred_gb))

    print("\nSVM Classification Report:")
    print(classification_report(y_test, y_pred_svm))

    print("\nNeural Network Classification Report:")
    print(classification_report(y_test, y_pred_nn))

    # Calculate F1 Score and AUC-ROC
    metrics = {
        'Gradient Boosting': {
            'F1 Score': f1_score(y_test, y_pred_gb),
            'AUC-ROC': roc_auc_score(y_test, gb.predict_proba(X_test)[:, 1])
        },
        'SVM': {
            'F1 Score': f1_score(y_test, y_pred_svm),
            'AUC-ROC': roc_auc_score(y_test, svm.predict_proba(X_test)[:, 1])
        },
        'Neural Network': {
            'F1 Score': f1_score(y_test, y_pred_nn),
            'AUC-ROC': roc_auc_score(y_test, nn.predict_proba(X_test)[:, 1])
        }
    }

    # Plot ROC curves
    plt.figure(figsize=(10, 8))
    for model, pred in [('Gradient Boosting', gb.predict_proba(X_test)[:, 1]),
                        ('SVM', svm.predict_proba(X_test)[:, 1]),
                        ('Neural Network', nn.predict_proba(X_test)[:, 1])]:
        fpr, tpr, _ = roc_curve(y_test, pred)
        plt.plot(fpr, tpr, label=f'{model} (AUC = {roc_auc_score(y_test, pred):.2f})')
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curves')
    plt.legend()
    plt.show()

    return metrics

# Generate insights for healthcare professionals
def generate_insights(metrics, selected_features):
    print("\nInsights for Healthcare Professionals:")
    print("1. The top features influencing heart disease prediction are:", selected_features.tolist())
    print("2. Gradient Boosting performed the best with an F1 Score of", metrics['Gradient Boosting']['F1 Score'], "and AUC-ROC of", metrics['Gradient Boosting']['AUC-ROC'])
    print("3. Regular health checkups focusing on these features can help in early detection and prevention.")
    print("4. Patients with high-risk predictions should be prioritized for further diagnostic tests and lifestyle interventions.")

# Main function
def main():
    # Load data
    filepath = 'heart_disease.csv'  # Replace with your dataset path
    data = load_data(filepath)

    # Perform EDA
    perform_eda(data)

    # Preprocess data
    X_train, X_test, y_train, y_test, selected_features = preprocess_data(data)

    # Train and evaluate models
    metrics = train_and_evaluate(X_train, X_test, y_train, y_test)

    # Generate insights
    generate_insights(metrics, selected_features)

if __name__ == "__main__":
    main()